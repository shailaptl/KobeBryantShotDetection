{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc\n",
    "key_id = 'AKIAJFE2NDK3RIPROO7Q'\n",
    "access_key = 'STjy90t/OqXVm+ScBYwLRqzpEKR5ZAB13JIsTZKeb'\n",
    "region = 'us-east-2'\n",
    "sc.setSystemProperty(\"com.amazonaws.services.s3.enableV4\", \"true\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.awsAccessKeyId\", key_id)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.awsSecretAccessKey\", access_key)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.\" + region + \".amazonaws.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Joe needs this\n",
    "if not 'sc' in globals():\n",
    "    from pyspark import SparkContext\n",
    "    sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loc_x: double (nullable = true)\n",
      " |-- loc_y: double (nullable = true)\n",
      " |-- period: double (nullable = true)\n",
      " |-- playoffs: double (nullable = true)\n",
      " |-- shot_distance: double (nullable = true)\n",
      " |-- shot_made_flag: double (nullable = true)\n",
      " |-- action_type:Alley Oop Dunk Shot: double (nullable = true)\n",
      " |-- action_type:Alley Oop Layup shot: double (nullable = true)\n",
      " |-- action_type:Cutting Finger Roll Layup Shot: double (nullable = true)\n",
      " |-- action_type:Cutting Layup Shot: double (nullable = true)\n",
      " |-- action_type:Driving Bank shot: double (nullable = true)\n",
      " |-- action_type:Driving Dunk Shot: double (nullable = true)\n",
      " |-- action_type:Driving Finger Roll Layup Shot: double (nullable = true)\n",
      " |-- action_type:Driving Finger Roll Shot: double (nullable = true)\n",
      " |-- action_type:Driving Floating Bank Jump Shot: double (nullable = true)\n",
      " |-- action_type:Driving Floating Jump Shot: double (nullable = true)\n",
      " |-- action_type:Driving Hook Shot: double (nullable = true)\n",
      " |-- action_type:Driving Jump shot: double (nullable = true)\n",
      " |-- action_type:Driving Layup Shot: double (nullable = true)\n",
      " |-- action_type:Driving Reverse Layup Shot: double (nullable = true)\n",
      " |-- action_type:Driving Slam Dunk Shot: double (nullable = true)\n",
      " |-- action_type:Dunk Shot: double (nullable = true)\n",
      " |-- action_type:Fadeaway Bank shot: double (nullable = true)\n",
      " |-- action_type:Fadeaway Jump Shot: double (nullable = true)\n",
      " |-- action_type:Finger Roll Layup Shot: double (nullable = true)\n",
      " |-- action_type:Finger Roll Shot: double (nullable = true)\n",
      " |-- action_type:Floating Jump shot: double (nullable = true)\n",
      " |-- action_type:Follow Up Dunk Shot: double (nullable = true)\n",
      " |-- action_type:Hook Bank Shot: double (nullable = true)\n",
      " |-- action_type:Hook Shot: double (nullable = true)\n",
      " |-- action_type:Jump Bank Shot: double (nullable = true)\n",
      " |-- action_type:Jump Hook Shot: double (nullable = true)\n",
      " |-- action_type:Jump Shot: double (nullable = true)\n",
      " |-- action_type:Layup Shot: double (nullable = true)\n",
      " |-- action_type:Pullup Bank shot: double (nullable = true)\n",
      " |-- action_type:Pullup Jump shot: double (nullable = true)\n",
      " |-- action_type:Putback Dunk Shot: double (nullable = true)\n",
      " |-- action_type:Putback Layup Shot: double (nullable = true)\n",
      " |-- action_type:Putback Slam Dunk Shot: double (nullable = true)\n",
      " |-- action_type:Reverse Dunk Shot: double (nullable = true)\n",
      " |-- action_type:Reverse Layup Shot: double (nullable = true)\n",
      " |-- action_type:Reverse Slam Dunk Shot: double (nullable = true)\n",
      " |-- action_type:Running Bank shot: double (nullable = true)\n",
      " |-- action_type:Running Dunk Shot: double (nullable = true)\n",
      " |-- action_type:Running Finger Roll Layup Shot: double (nullable = true)\n",
      " |-- action_type:Running Finger Roll Shot: double (nullable = true)\n",
      " |-- action_type:Running Hook Shot: double (nullable = true)\n",
      " |-- action_type:Running Jump Shot: double (nullable = true)\n",
      " |-- action_type:Running Layup Shot: double (nullable = true)\n",
      " |-- action_type:Running Pull-Up Jump Shot: double (nullable = true)\n",
      " |-- action_type:Running Reverse Layup Shot: double (nullable = true)\n",
      " |-- action_type:Running Slam Dunk Shot: double (nullable = true)\n",
      " |-- action_type:Running Tip Shot: double (nullable = true)\n",
      " |-- action_type:Slam Dunk Shot: double (nullable = true)\n",
      " |-- action_type:Step Back Jump shot: double (nullable = true)\n",
      " |-- action_type:Tip Layup Shot: double (nullable = true)\n",
      " |-- action_type:Tip Shot: double (nullable = true)\n",
      " |-- action_type:Turnaround Bank shot: double (nullable = true)\n",
      " |-- action_type:Turnaround Fadeaway Bank Jump Shot: double (nullable = true)\n",
      " |-- action_type:Turnaround Fadeaway shot: double (nullable = true)\n",
      " |-- action_type:Turnaround Finger Roll Shot: double (nullable = true)\n",
      " |-- action_type:Turnaround Hook Shot: double (nullable = true)\n",
      " |-- action_type:Turnaround Jump Shot: double (nullable = true)\n",
      " |-- shot_zone_area:Back Court(BC): double (nullable = true)\n",
      " |-- shot_zone_area:Center(C): double (nullable = true)\n",
      " |-- shot_zone_area:Left Side Center(LC): double (nullable = true)\n",
      " |-- shot_zone_area:Left Side(L): double (nullable = true)\n",
      " |-- shot_zone_area:Right Side Center(RC): double (nullable = true)\n",
      " |-- shot_zone_area:Right Side(R): double (nullable = true)\n",
      " |-- shot_zone_basic:Above the Break 3: double (nullable = true)\n",
      " |-- shot_zone_basic:Backcourt: double (nullable = true)\n",
      " |-- shot_zone_basic:In The Paint (Non-RA): double (nullable = true)\n",
      " |-- shot_zone_basic:Left Corner 3: double (nullable = true)\n",
      " |-- shot_zone_basic:Mid-Range: double (nullable = true)\n",
      " |-- shot_zone_basic:Restricted Area: double (nullable = true)\n",
      " |-- shot_zone_basic:Right Corner 3: double (nullable = true)\n",
      " |-- opponent:ATL: double (nullable = true)\n",
      " |-- opponent:BKN: double (nullable = true)\n",
      " |-- opponent:BOS: double (nullable = true)\n",
      " |-- opponent:CHA: double (nullable = true)\n",
      " |-- opponent:CHI: double (nullable = true)\n",
      " |-- opponent:CLE: double (nullable = true)\n",
      " |-- opponent:DAL: double (nullable = true)\n",
      " |-- opponent:DEN: double (nullable = true)\n",
      " |-- opponent:DET: double (nullable = true)\n",
      " |-- opponent:GSW: double (nullable = true)\n",
      " |-- opponent:HOU: double (nullable = true)\n",
      " |-- opponent:IND: double (nullable = true)\n",
      " |-- opponent:LAC: double (nullable = true)\n",
      " |-- opponent:MEM: double (nullable = true)\n",
      " |-- opponent:MIA: double (nullable = true)\n",
      " |-- opponent:MIL: double (nullable = true)\n",
      " |-- opponent:MIN: double (nullable = true)\n",
      " |-- opponent:NJN: double (nullable = true)\n",
      " |-- opponent:NOH: double (nullable = true)\n",
      " |-- opponent:NOP: double (nullable = true)\n",
      " |-- opponent:NYK: double (nullable = true)\n",
      " |-- opponent:OKC: double (nullable = true)\n",
      " |-- opponent:ORL: double (nullable = true)\n",
      " |-- opponent:PHI: double (nullable = true)\n",
      " |-- opponent:PHX: double (nullable = true)\n",
      " |-- opponent:POR: double (nullable = true)\n",
      " |-- opponent:SAC: double (nullable = true)\n",
      " |-- opponent:SAS: double (nullable = true)\n",
      " |-- opponent:SEA: double (nullable = true)\n",
      " |-- opponent:TOR: double (nullable = true)\n",
      " |-- opponent:UTA: double (nullable = true)\n",
      " |-- opponent:VAN: double (nullable = true)\n",
      " |-- opponent:WAS: double (nullable = true)\n",
      " |-- season: double (nullable = true)\n",
      " |-- matchup: double (nullable = true)\n",
      " |-- time_remaining: double (nullable = true)\n",
      " |-- game_date: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc_sql = SQLContext(sc)\n",
    "df = sc_sql.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load(\"preprocessed.csv\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_rdd = df.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd_train, rdd_test = df_rdd.randomSplit(weights=[.8, .2], seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "EXCLUDE = [\"shot_made_flag\", \"period\", \"matchup\"]\n",
    "#FEATURES = [\"action_type\", \"loc_x\", \"loc_y\", \"time_remaining\", \"playoffs\", \"season\", \"shot_zone_area\", \"shot_distance\", \"shot_zone_basic\", \"game_date\"]\n",
    "FEATURES = [x for x in df.columns if x not in EXCLUDE]\n",
    "\n",
    "def toLP(row):\n",
    "    features = []\n",
    "    \n",
    "    for feat in FEATURES:\n",
    "        features.append(row[feat])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return LabeledPoint(row[\"shot_made_flag\"], features)\n",
    "\n",
    "\n",
    "rdd_train = rdd_train.map(toLP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "\n",
    "def toVector(row):\n",
    "    features = []\n",
    "    \n",
    "    for feat in FEATURES:\n",
    "        features.append(row[feat])\n",
    "        \n",
    "    return array(features)\n",
    "\n",
    "def toLabel(row):\n",
    "    return row[\"shot_made_flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd_test_feats = rdd_test.map(toVector)\n",
    "rdd_test_labels = rdd_test.map(toLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_predictions(labelPreds):\n",
    "    total = labelPreds.count()\n",
    "    true_pos = labelPreds.filter(lambda labpred: float(labpred[0]) == 1 and labpred[1] == 1).count()\n",
    "    false_pos = labelPreds.filter(lambda labpred: float(labpred[0]) == 0 and labpred[1] == 1).count()\n",
    "    false_neg= labelPreds.filter(lambda labpred: float(labpred[0]) == 1 and labpred[1] == 0).count()\n",
    "    true_neg = labelPreds.filter(lambda labpred: float(labpred[0]) == 0 and labpred[1] == 0).count()\n",
    "    print(\"Total: \" + str(total))\n",
    "    print(\"Precision: \" + str(true_pos/(true_pos+false_pos)))\n",
    "    print(\"Recall: \" + str(true_pos/(true_pos+false_neg)))\n",
    "    print(\"Accuracy: \" + str((true_pos+true_neg)/total))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import DecisionTree\n",
    "dt = DecisionTree.trainClassifier(rdd_train, 2, {}, impurity='gini', maxDepth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = dt.predict(rdd_test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelPreds = rdd_test_labels.zip(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = labelPreds.filter(lambda labpred: float(labpred[0]) == labpred[1]).count() / float(rdd_test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6570660522273426"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 5208\n",
      "Precision: 0.682175622542595\n",
      "Recall: 0.44128868164476476\n",
      "Accuracy: 0.6543778801843319\n"
     ]
    }
   ],
   "source": [
    "evaluate_predictions(labelPreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import NaiveBayes, NaiveBayesModel\n",
    "nb = NaiveBayes.train(rdd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_predictions = nb.predict(rdd_test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_labelPreds = rdd_test_labels.zip(nb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_acc = nb_labelPreds.filter(lambda labpred: float(labpred[0]) == labpred[1]).count() / float(rdd_test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_acc\n",
    "evaluate_predictions(nb_labelPreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TreeEnsembleModel classifier with 20 trees\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.tree import RandomForest\n",
    "\n",
    "rf = RandomForest.trainClassifier(rdd_train, numClasses=2, categoricalFeaturesInfo={}, numTrees=20, maxDepth=15)\n",
    "\n",
    "print(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = rf.predict(rdd_test_feats)\n",
    "labelPreds = rdd_test_labels.zip(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6541858678955453"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = labelPreds.filter(lambda labpred: float(labpred[0]) == labpred[1]).count() / float(rdd_test.count())\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45314900153609833\n",
      "Total: 5208\n",
      "Precision: 0.4525687896863575\n",
      "Recall: 1.0\n",
      "Accuracy: 0.45161290322580644\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "\n",
    "svm = SVMWithSGD.train(rdd_train, iterations=100)\n",
    "predictions = svm.predict(rdd_test_feats)\n",
    "labelPreds = rdd_test_labels.zip(predictions)\n",
    "\n",
    "acc = labelPreds.filter(lambda labpred: float(labpred[0]) == labpred[1]).count() / float(rdd_test.count())\n",
    "print(acc)\n",
    "evaluate_predictions(labelPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RDD' object has no attribute '_jdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e2b0f52ebfbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBinaryClassificationEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryClassificationEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test Area Under ROC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelPreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \"\"\"\n\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0misLargerBetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RDD' object has no attribute '_jdf'"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print('Test Area Under ROC', evaluator.evaluate(labelPreds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3791a593e0b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMultilayerPerceptronClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMulticlassClassificationEvaluator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultilayerPerceptronClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxIter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblockSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1234\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrdd_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "model = trainer.fit(rdd_train)\n",
    "result = model.transform(rdd_test_feats)\n",
    "predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
